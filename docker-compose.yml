services:
  mrst:
    build:
      context: .devcontainer/mrst
      dockerfile: Dockerfile
    container_name: eagle-west-mrst
    volumes:
      - .:/workspace
    working_dir: /workspace
    environment:
      - CLAUDE_SKIP_PERMISSIONS_CHECK=true
      - ANTHROPIC_SKIP_PERMS=true
      - CLAUDE_CLI_YOLO=true
    tty: true
    stdin_open: true
    profiles:
      - mrst
      - all

  opm:
    build:
      context: .devcontainer/opm
      dockerfile: Dockerfile
    container_name: eagle-west-opm
    volumes:
      - .:/workspace
    working_dir: /workspace
    environment:
      - CLAUDE_SKIP_PERMISSIONS_CHECK=true
      - ANTHROPIC_SKIP_PERMS=true
      - CLAUDE_CLI_YOLO=true
    tty: true
    stdin_open: true
    profiles:
      - opm
      - all

  tensorflow:
    build:
      context: .devcontainer/tensorflow
      dockerfile: Dockerfile
    container_name: eagle-west-tensorflow
    volumes:
      - .:/workspace
    working_dir: /workspace
    environment:
      - CLAUDE_SKIP_PERMISSIONS_CHECK=true
      - ANTHROPIC_SKIP_PERMS=true
      - CLAUDE_CLI_YOLO=true
    ports:
      - "8888:8888"  # Jupyter
      - "6006:6006"  # TensorBoard
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    tty: true
    stdin_open: true
    profiles:
      - tensorflow
      - all

  pytorch:
    build:
      context: .devcontainer/pytorch
      dockerfile: Dockerfile
    container_name: eagle-west-pytorch
    volumes:
      - .:/workspace
    working_dir: /workspace
    environment:
      - CLAUDE_SKIP_PERMISSIONS_CHECK=true
      - ANTHROPIC_SKIP_PERMS=true
      - CLAUDE_CLI_YOLO=true
    ports:
      - "8889:8888"  # Jupyter (different port to avoid conflict)
      - "6007:6006"  # TensorBoard (different port)
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    tty: true
    stdin_open: true
    profiles:
      - pytorch
      - all

# Usage examples:
# Build and run MRST only:      docker-compose --profile mrst up -d
# Build and run OPM only:       docker-compose --profile opm up -d
# Build and run TensorFlow:     docker-compose --profile tensorflow up -d
# Build and run PyTorch:        docker-compose --profile pytorch up -d
# Build and run all:           docker-compose --profile all up -d
# Access container shell:       docker exec -it eagle-west-[service] bash